{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "jAmOLs1iSzsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "kpeTzoL9bBr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from mpl_toolkits import mplot3d\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.datasets import load_iris\n",
        "import seaborn as sns\n",
        "from scipy.stats import kde"
      ],
      "metadata": {
        "id": "UGvnOPubaOWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***EXPLORATORY DATA ANALYSIS***"
      ],
      "metadata": {
        "id": "Xa9BsPXXaV67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = pd.read_csv('/content/drive/MyDrive/Iris.csv')"
      ],
      "metadata": {
        "id": "2LhFvOlcYn8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.keys()"
      ],
      "metadata": {
        "id": "fFvYWaMiYu4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.info()"
      ],
      "metadata": {
        "id": "2ukuL8t2Y07U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.head()"
      ],
      "metadata": {
        "id": "ylr_Nja2Y61J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.shape"
      ],
      "metadata": {
        "id": "0gjVwQ41ZC7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.Species.value_counts()"
      ],
      "metadata": {
        "id": "mRMBcG45ZGIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CLEANING THE DATA SET***"
      ],
      "metadata": {
        "id": "UYwOqBae7gZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# missing values\n",
        "missing = iris.isnull().sum()\n",
        "print(missing)\n",
        "\n",
        "# Check if there are any missing values\n",
        "if missing.any():\n",
        "    print(\"\\nMissing values found in the dataset:\")\n",
        "    print(missing[missing > 0])  # Display only columns with missing values\n",
        "else:\n",
        "    print('\\nThere are no missing values in the dataset')"
      ],
      "metadata": {
        "id": "KUZwNFWg82NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values\n",
        "iris.nunique()"
      ],
      "metadata": {
        "id": "O-xrc3n29Qle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***DUPLICATES IDENTIFY***"
      ],
      "metadata": {
        "id": "03a655yw-AEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# duplicate values\n",
        "duplicates = iris.duplicated().sum()\n",
        "print(f\"Number of duplicate rows = {duplicates}\")\n",
        "\n",
        "# drop duplicates\n",
        "print(\"After dropping duplicates\")\n",
        "iris.drop_duplicates(inplace=True)\n",
        "print(f\"Number of duplicate rows = {iris.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "iu7h1cgE-PRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***PRE - PROCESSING THE DATA SET***"
      ],
      "metadata": {
        "id": "1Gt4dUHNC0CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete a column only if it exists\n",
        "iris.drop(['Id'], axis=1, inplace=True)\n",
        "iris.head()"
      ],
      "metadata": {
        "id": "Mk968uVT7nI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***VISUALIZATIONS***"
      ],
      "metadata": {
        "id": "KuQqby6HDaR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Create pairplot to visualize relationships between features\n",
        "sns.pairplot(iris, hue='Species', diag_kind='hist')\n",
        "plt.suptitle('Iris Features Pairplot', y=1.02)"
      ],
      "metadata": {
        "id": "umUDol58oAQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='PetalLengthCm', y='PetalWidthCm', hue='Species', data=iris, palette='Set2')\n",
        "\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Petal Length (cm)')\n",
        "plt.ylabel('Petal Width (cm)')\n",
        "plt.title('Scatter Plot of Petal Length vs. Petal Width')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lfc_Or4alyKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'iris' is your DataFrame and 'Species' is a column with species names\n",
        "Species = iris['Species'].value_counts().reset_index()\n",
        "Species.columns = ['Species', 'count']\n",
        "\n",
        "# Create the pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(Species['count'],\n",
        "        labels=['Iris-setosa','Iris-versicolor','Iris-virginica'],  # Use actual species names here\n",
        "        autopct='%1.1f%%',\n",
        "        explode=[0.05, 0.05, 0.05],\n",
        "        shadow=True,\n",
        "        startangle=90)\n",
        "\n",
        "plt.title('Distribution of Iris Flower Species')\n",
        "plt.legend(title=\"Iris flower species\", loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hNfV706Id30m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create correlation heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(iris.drop(columns=['Species']).corr(), annot=True, cmap='coolwarm') # Drop the 'species' column\n",
        "plt.title('Feature Correlation Matrix')"
      ],
      "metadata": {
        "id": "fiuGwBBIJgFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NGv04oNOwfMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ENCODE THE TARGET VARABLE***"
      ],
      "metadata": {
        "id": "1GczSVYjzqkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the target variable\n",
        "iris['Species'] = iris['Species'].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "vmVXZ1DIgPeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***SPLIT THE DATA SET***"
      ],
      "metadata": {
        "id": "IAKzoCYM1aH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features and target\n",
        "X = iris.drop(['Species'], axis=1)\n",
        "y = iris['Species']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ZcakXbJ1gKBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "hi0MilCOmFZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Train and Evaluate Machine Learning Models***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y1TtCemEtzJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***LOGISTIC REGRESSION***"
      ],
      "metadata": {
        "id": "iWYvUB1Bz89a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "9ciavjIdmahk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "QcydlFh3mdcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter search space\n",
        "param_dist = {\n",
        "\t'C': np.logspace(-4, 4, 100), # Range of C values in logarithmic scale\n",
        "\t'penalty': ['l2'], # Only 'l2' penalty is compatible with 'lbfgs' solver\n",
        "\t'solver': ['lbfgs'] # Use only 'lbfgs' solver\n",
        "}"
      ],
      "metadata": {
        "id": "ZAbku_aGmhuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "r_hmBHwhml8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Logistic Regression model\n",
        "logistic_regression = LogisticRegression(max_iter=1000)"
      ],
      "metadata": {
        "id": "bJ6c6oKkmtRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "8ES5IXXfmyzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform RandomizedSearchCV with error_score='raise'\n",
        "random_search = RandomizedSearchCV(logistic_regression, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42, error_score='raise')\n",
        "random_search.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "aacUkaMtm2SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_"
      ],
      "metadata": {
        "id": "JheO1eOjm7Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with the best hyperparameters on the entire dataset\n",
        "best_model = random_search.best_estimator_\n",
        "best_model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "UrsdRna4m-cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=best_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "E7HeAMjVnF9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_test to a NumPy array\n",
        "y_test_array = y_test.to_numpy()\n",
        "\n",
        "# Reshape y_pred and y_test to have the same dimension\n",
        "y_pred_reshaped = y_pred.reshape(len(y_pred),1)\n",
        "y_test_reshaped = y_test_array.reshape(len(y_test_array),1)\n",
        "\n",
        "# Concatenate the reshaped arrays\n",
        "result = np.concatenate((y_pred_reshaped, y_test_reshaped), axis=1)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "2qWX_ZJlnJ5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model on the test set\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "-ViT-NMOnPqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy=accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Accuracy on test set: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "ekmx-Zd-nTcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)"
      ],
      "metadata": {
        "id": "Ng7xmNctnc_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ... (rest of your code) ...\n",
        "\n",
        "# Before plotting the confusion matrix, initialize and fit LabelEncoder:\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(iris['Species'])  # Fit to the original 'Species' column before encoding\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rop4QHcFnwF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Calculate the classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "id": "pGu7fIUHn4Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***K-NEAREST NEIGHBORS (KNN)***"
      ],
      "metadata": {
        "id": "Gb0yTdKxspjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV # Import RepeatedStratifiedKFold and GridSearchCV"
      ],
      "metadata": {
        "id": "498WZgN9sqR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define models and parameters\n",
        "model = KNeighborsClassifier()\n",
        "n_neighbors = range(1, 21, 2)\n",
        "weights = ['uniform', 'distance']\n",
        "metric = ['euclidean', 'manhattan', 'minkowski']\n",
        "# define grid search\n",
        "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "rPc04B6ssx4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the KNeighborsClassifier with the best parameters\n",
        "best_params = grid_result.best_params_\n",
        "model_KNN = KNeighborsClassifier(**best_params)\n",
        "model_KNN.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "GE-dA5-XtDzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on the training set\n",
        "y_pred_KNN = model_KNN.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_KNN)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_train_pred_KNN = model_KNN.predict(X_train_scaled)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred_KNN)\n",
        "print(\"Training Accuracy:\", train_accuracy)"
      ],
      "metadata": {
        "id": "qIAD1y8ftHG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix on test set\n",
        "cm = confusion_matrix(y_pred_KNN, y_test)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CPVWQMcntK_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred_KNN, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)"
      ],
      "metadata": {
        "id": "YYVkWC3btRx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the classification report\n",
        "report = classification_report(y_test, y_pred_KNN)\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "id": "1IEDH96JtWcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***support vector machine***  (svm)"
      ],
      "metadata": {
        "id": "yJEdjXFltvRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "aD8teMqBtwgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model and parameters\n",
        "model = SVC()\n",
        "kernel = ['poly', 'rbf', 'sigmoid']\n",
        "C = [50, 10, 1.0, 0.1, 0.01]\n",
        "gamma = ['scale']\n",
        "# define grid search\n",
        "grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "oll_NRbutw6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the SVM  with the best parameters\n",
        "best_params = grid_result.best_params_\n",
        "model_SVM = SVC(**best_params)\n",
        "model_SVM.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "L8A7dXbEtw2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on the training set\n",
        "y_pred_SVM = model_SVM.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_SVM)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_train_pred_SVM = model_SVM.predict(X_train_scaled)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred_SVM)\n",
        "print(\"Training Accuracy:\", train_accuracy)"
      ],
      "metadata": {
        "id": "gCpWYc_mtwzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix on test set\n",
        "cm = confusion_matrix(y_test, y_pred_SVM)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yHgaFErgtwwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision_SVM = precision_score(y_test, y_pred_SVM, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision_SVM)"
      ],
      "metadata": {
        "id": "wnJvfDjctwsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score # Import recall_score\n",
        "\n",
        "# Change the average parameter to 'micro', 'macro', or 'weighted'\n",
        "recall_score(y_test, y_pred_SVM, average='micro')"
      ],
      "metadata": {
        "id": "GJOKZH2Tuj3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the classification report\n",
        "report = classification_report(y_test, y_pred_SVM)\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "id": "eV2iyT4luyV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CHOOSE THE BEST MODEL***"
      ],
      "metadata": {
        "id": "8JDE-DCQvzSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary to store model predictions\n",
        "model_predictions = {}\n",
        "\n",
        "# Assuming you have predictions from models named 'Logistic Regression', 'KNN', and 'SVM'\n",
        "# Store the predictions in the dictionary\n",
        "model_predictions['Logistic Regression'] = y_pred # Assuming 'y_pred' is from Logistic Regression\n",
        "model_predictions['KNN'] = y_pred_KNN\n",
        "model_predictions['SVM'] = y_pred_SVM\n",
        "\n",
        "# Calculate and store accuracy scores\n",
        "accuracy_scores = {}\n",
        "for model_name, y_pred in model_predictions.items():\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores[model_name] = accuracy"
      ],
      "metadata": {
        "id": "ye41-ep6vpJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best model\n",
        "best_model_name = max(accuracy_scores, key=accuracy_scores.get)\n",
        "\n",
        "# Print the best model and its accuracy\n",
        "print(f\"The best model is: {best_model_name} with an accuracy of {accuracy_scores[best_model_name]:.2f}\")"
      ],
      "metadata": {
        "id": "U8C4WU1Dvu94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Conclusion***\n",
        "Both Logistic Regression and KNN achieved an accuracy of 1.0 on the Iris dataset, indicating that they perfectly classified all instances in the test set.The code evaluates both models and prints their accuracies, classification reports, and confusion matrices.\n",
        "It concludes by comparing the accuracies and suggests the best model based on the criteria discussed.\n",
        "This structured approach allows you to effectively compare the performance of Logistic Regression and KNN on the Iris dataset while considering their computational efficiency and suitability for the problem at hand."
      ],
      "metadata": {
        "id": "17rAJ8Zry_Ve"
      }
    }
  ]
}